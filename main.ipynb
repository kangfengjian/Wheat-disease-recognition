{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a5b61b-442b-4cf4-9875-f03382de20ff",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "1. 准备数据集，将数据集处理为目标组织结构\n",
    "2. 加载数据集（定义数据处理类）构建一个获取数据集的类。记住，它派生自Dataset类，需要三个神奇的函数——__init__、__getitem__和__len__，它们始终被定义为：定义数据集加载器，设定批大小等。\n",
    "3. 模型定义，或许可以加上损失函数定义优化方法定义\n",
    "4. 训练代码\n",
    "5. 测试代码\n",
    "6. 推理代码\n",
    "7. 准确率评估代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f16cb4-3ff1-4768-ae1f-f3fc9507cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入依赖\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import os\n",
    "import skimage\n",
    "import torchvision.datasets.mnist as mnist\n",
    "import numpy\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import shutil\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b77a68e0-5f2f-41f6-97fe-fe0a62526f1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 26.4M/26.4M [00:33<00:00, 800kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data/FMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 29.5k/29.5k [00:00<00:00, 132kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/FMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4.42M/4.42M [00:05<00:00, 839kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/FMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5.15k/5.15k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/FMNIST\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data/FMNIST\n",
       "    Split: Test"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备数据\n",
    "def prepare_data():\n",
    "    '''要根据不同的需求整理数据的组织形式'''\n",
    "    datasets.FashionMNIST(root = './data/FMNIST', download=True, train=False)\n",
    "    root = \"./data/Fashion-MNIST\" \n",
    "    train_set = (\n",
    "        mnist.read_image_file(os.path.join(root, 'train-images-idx3-ubyte')),\n",
    "        mnist.read_label_file(os.path.join(root, 'train-labels-idx1-ubyte'))\n",
    "    )\n",
    "    test_set = (\n",
    "        mnist.read_image_file(os.path.join(root,'t10k-images-idx3-ubyte')),\n",
    "        mnist.read_label_file(os.path.join(root,'t10k-labels-idx1-ubyte'))\n",
    "    )\n",
    "    print(\"train set:\", train_set[0].size())\n",
    "    print(\"test set:\", test_set[0].size())\n",
    "    \n",
    "    def convert_to_img(train=True):\n",
    "        if(train):\n",
    "            f = open(root + '/train.txt', 'w')\n",
    "            data_path = root + '/train/'\n",
    "            if(not os.path.exists(data_path)):\n",
    "                os.makedirs(data_path)\n",
    "            for i, (img, label) in enumerate(zip(train_set[0], train_set[1])):\n",
    "                img_path = data_path + str(i) + '.jpg'\n",
    "                cv2.imwrite(img_path, img.numpy())\n",
    "                int_label = str(label).replace('tensor(', '')\n",
    "                int_label = int_label.replace(')', '')\n",
    "                f.write(str(i) + '.jpg' + ' ' + str(int_label) + '\\n')\n",
    "            f.close()\n",
    "        else:\n",
    "            f = open(root + '/test.txt', 'w')\n",
    "            data_path = root + '/test/'\n",
    "            if (not os.path.exists(data_path)):\n",
    "                os.makedirs(data_path)\n",
    "            for i, (img, label) in enumerate(zip(test_set[0], test_set[1])):\n",
    "                img_path = data_path + str(i) + '.jpg'\n",
    "                cv2.imwrite(img_path, img.numpy())\n",
    "                int_label = str(label).replace('tensor(', '')\n",
    "                int_label = int_label.replace(')', '')\n",
    "                f.write(str(i) + '.jpg' + ' ' + str(int_label) + '\\n')\n",
    "            f.close()\n",
    "    convert_to_img(True)\n",
    "    convert_to_img(False)\n",
    "    d = {'0': 'T-shirt',\n",
    "    '1': 'Trouser',\n",
    "    '2': 'Pullover',\n",
    "    '3': 'Dress',\n",
    "    '4': 'Coat',\n",
    "    '5': 'Sandal',\n",
    "    '6': 'Shirt',\n",
    "    '7': 'Sneaker',\n",
    "    '8': 'Bag',\n",
    "    '9': 'Ankle boot',}\n",
    "    with open('./data/Fashion-MNIST/test.txt', 'r') as rf:\n",
    "        text=rf.read().split('\\n')\n",
    "        for i in range(len(text)):\n",
    "            if text[i].strip():\n",
    "                name,cla = text[i].split()\n",
    "                # print(text[i].split())\n",
    "                shutil.move('./data/Fashion-MNIST/test/'+name,'./data/Fashion-MNIST/test/{}/{}'.format(d[cla],name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd7cf0-61c5-42d4-bce7-9a1d15d7c3f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 数据加载\n",
    "# 主要是写一个类，然后写加载器，是pytorch中自带的        \n",
    "class TrafficSign(Dataset):  \n",
    "    def __init__(self, data_file, dataset_root):  \n",
    "        self.transforms = [\n",
    "            lambda x:x,\n",
    "            transforms.RandomHorizontalFlip(),  # 左右翻转\n",
    "            transforms.RandomVerticalFlip(),  # 垂直翻转\n",
    "            transforms.RandomRotation((45,45)),   # 旋转45度\n",
    "            transforms.RandomRotation((90,90)),   # 旋转45度\n",
    "            transforms.RandomRotation((135,135)),   # 旋转45度\n",
    "            transforms.RandomRotation((180,180)),   # 旋转45度\n",
    "            transforms.RandomRotation((225,225)),   # 旋转45度\n",
    "            transforms.RandomRotation((270,270)),   # 旋转45度\n",
    "            transforms.RandomRotation((315,315)),   # 旋转45度\n",
    "            transforms.RandomAffine(0,translate=(0.3,0.3)),  # 平移\n",
    "            transforms.RandomAffine(0,translate=(0.3,0.3)),  # 平移\n",
    "            transforms.RandomAffine(0,translate=(0.3,0.3)),  # 平移\n",
    "            transforms.RandomAffine(0,translate=(0.3,0.3)),  # 平移\n",
    "            lambda x:transforms.Resize((x.size[0], x.size[1]//2))(x),   # 横向缩放\n",
    "            lambda x:transforms.Resize((x.size[0]//2, x.size[1]))(x),   # 纵向缩放\n",
    "            transforms.GaussianBlur(7, 3),  # 高斯模糊\n",
    "            lambda x:Image.fromarray(iaa.MotionBlur(k=15, angle=0)(image = np.array(x)[:, :, ::-1] )),  # 运动模糊\n",
    "            lambda x:transforms.Resize((30, 30))(transforms.ColorJitter(brightness=0.1, contrast=0.1)(x)), # 降低亮度并缩小\n",
    "            ]\n",
    "        with open(data_file,'r',encoding='utf-8') as rf:\n",
    "            self.data = list()\n",
    "            for pic in [i.split(',') for i in rf.read().split('\\n') if i]:\n",
    "                for j in range(len(self.transforms)):\n",
    "                    if int(pic[1]) in [21,23,25,26,27,28,33,34,50,53,55] and j in [1]:\n",
    "                        continue\n",
    "                    self.data.append([pic[0]+'_{}'.format(j),pic[1]])\n",
    "        self.dataset_root = dataset_root\n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):  \n",
    "        sample = self.data[idx]\n",
    "        img = Image.open(self.dataset_root/Path(sample[0][:sample[0].rfind('_')])) # 打开图片，\n",
    "        img = img.convert('RGB')   # 首先统一为RGB的形式，然后进行处理\n",
    "        img = self.transforms[int(sample[0][sample[0].rfind('_')+1:])](img) # 数据增强处理  \n",
    "        img = img.convert('L') # 改为单通道\n",
    "        img = transforms.Resize((96, 96))(img) # 统一大小\n",
    "        img = transforms.ToTensor()(img) \n",
    "        y = int(sample[1])\n",
    "        return img,y\n",
    "\n",
    "train_dataset = TrafficSign(data_root/'train_{}.csv'.format(cross_index),datasets_root)\n",
    "train_iter = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_dataset = TrafficSign(data_root/'test_{}.csv'.format(cross_index),datasets_root)\n",
    "test_iter = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39efeb-f7be-4778-9a71-6d720201264d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 模型定义GooGLeNet\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms  \n",
    "from sklearn.model_selection import train_test_split # pip install scikit-learn \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from PIL import Image  \n",
    "import json\n",
    "from datetime import datetime\n",
    "import argparse \n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(14, 10),model_name='',index=''):\n",
    "        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "        self.model_name=model_name\n",
    "        self.index = index\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        self.fig.savefig('log/log_{}_{}.png'.format(self.model_name,self.index))\n",
    "\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    # `c1`--`c4` 是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最⼤汇聚层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)\n",
    "    \n",
    "b1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                    Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                    Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                    Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                    Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                    Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                    Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_ch6(train_iter,test_iter,num_epochs,lr,device,model_name,index):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m)==nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 62))\n",
    "    net.apply(init_weights)\n",
    "    print('train on', device)\n",
    "    # print('模型yi转移到GPU',torch.cuda.memory_allocated()//1024//1024)\n",
    "    net.to(device)\n",
    "    # print('转移zyi完成',torch.cuda.memory_allocated()//1024//1024)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = Animator(xlabel='epoch',xlim=[1,num_epochs],legend=['train loss','train acc','test acc'],model_name=model_name,index=index)\n",
    "    # timer,num_batches = d2l.Timer(),len(train_iter)\n",
    "    num_batches = len(train_iter)\n",
    "    best_acc = 0\n",
    "    # print(num_batches)\n",
    "    with open('log/log_{}_{}.log'.format(model_name,index),'w',encoding='utf-8') as wf:\n",
    "        wf.write('')\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.perf_counter()\n",
    "        out_str = '{}-cross_{}_epoch:{}/{}\\t'.format(model_name,index,epoch,num_epochs)\n",
    "        # print('epoch:{}'.format(epoch),end='\\t')\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i,(X,y) in enumerate(train_iter):\n",
    "            # timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            # print('开始转移本batch的数据',torch.cuda.memory_allocated()//1024//1024)\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            # print('本batch的数据转移完成',torch.cuda.memory_allocated()//1024//1024)\n",
    "            y_hat = net(X)\n",
    "            # print('本batch获得预测结果',torch.cuda.memory_allocated()//1024//1024)\n",
    "            # print(y_hat.shape)\n",
    "            # print(y_hat)\n",
    "            # print(y.shape)\n",
    "            # print(y)\n",
    "            # quit()\n",
    "            l = loss(y_hat,y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l*X.shape[0],d2l.accuracy(y_hat,y),X.shape[0])\n",
    "            # timer.stop()\n",
    "            train_l = metric[0]/metric[2]\n",
    "            train_acc = metric[1]/metric[2]\n",
    "            if (i+1)%(num_batches//5)==0 or i==num_batches-1:\n",
    "                animator.add(epoch+(i+1)/num_batches,(train_l,train_acc,None))\n",
    "        test_acc = evaluate_accuracy_gpu(net,test_iter)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc = test_acc\n",
    "            weights_path = Path('./weights/')\n",
    "            weights_path.mkdir(parents=True, exist_ok=True)\n",
    "            if best_acc>0.0:\n",
    "                torch.save(net.state_dict(),weights_path/Path('{}_{}_best_weights.pth'.format(model_name,index)))\n",
    "        # torch.save(net.state_dict(), weights_path/Path('{}_{}_last_weights.pth'.format(model_name,index)))\n",
    "        animator.add(epoch+1,(None,None,test_acc))\n",
    "        with open('log/log_{}_{}.log'.format(model_name,index),'a',encoding='utf-8') as wf:\n",
    "            wf.write(out_str+'\\n')\n",
    "        # print('本epoch结束',torch.cuda.memory_allocated()//1024//1024)\n",
    "        process_time = time.perf_counter()-start_time\n",
    "        out_str+=f'loss {train_l:.3f},train acc {train_acc:.3f},'f'test acc {test_acc:.3f},'f'time {process_time:.3f}s'\n",
    "        print(out_str)\n",
    "\n",
    "    \n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使⽤GPU计算模型在数据集上的精度。\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval() # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X, list):\n",
    "            # BERT微调所需的（之后将介绍）\n",
    "            X = [x.to(device) for x in X]\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def dataset(data_root):\n",
    "    '''准备数据集\n",
    "    '''\n",
    "    data_root.mkdir(parents=True, exist_ok=True)\n",
    "    # 检查是否存在训练集文件,没有则创建\n",
    "    if not (data_root/Path('train_set')).exists():\n",
    "        datasets.utils.download_and_extract_archive('https://ai-contest-static.xfyun.cn/2024/%E4%BA%A4%E9%80%9A%E6%A0%87%E8%AF%86%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%E8%B5%9B/train_set.zip',data_root,data_root)\n",
    "    if not (data_root/Path('test_set')).exists():\n",
    "        datasets.utils.download_and_extract_archive('https://ai-contest-static.xfyun.cn/2024/%E4%BA%A4%E9%80%9A%E6%A0%87%E8%AF%86%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%E8%B5%9B/test_set.zip',data_root,data_root)\n",
    "    if not (data_root/Path('example.csv')).exists():\n",
    "        datasets.utils.download_url('https://ai-contest-static.xfyun.cn/2024/%E4%BA%A4%E9%80%9A%E6%A0%87%E8%AF%86%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%E8%B5%9B/example.csv',data_root)\n",
    "\n",
    "class TrafficSign(Dataset):  \n",
    "    def __init__(self, datasets_root, data_root, data='train', lable=True):  \n",
    "        self.data_type = data\n",
    "        if data=='train':\n",
    "            with open(data_root/Path('train.csv'),'r',encoding='utf-8') as rf:\n",
    "                self.data = [i.split(',') for i in rf.read().split('\\n')]\n",
    "        elif data=='val':\n",
    "            with open(data_root/Path('val.csv'),'r',encoding='utf-8') as rf:\n",
    "                self.data = [i.split(',') for i in rf.read().split('\\n')]\n",
    "        elif data=='test':\n",
    "            with open(data_root/Path('test.csv'),'r',encoding='utf-8') as rf:\n",
    "                self.data = [[i,Path(i).name] for i in rf.read().split('\\n')]\n",
    "        else:\n",
    "            assert '未知data类型：{}'.format(data) \n",
    "        with open(data_root/Path('classes.txt'),'r',encoding='utf-8') as rf:\n",
    "            self.classes = rf.read().split(',')\n",
    "        self.datasets_root = datasets_root\n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):  \n",
    "        sample = self.data[idx]\n",
    "        img = Image.open(self.datasets_root/Path(sample[0]))\n",
    "        # 图片处理\n",
    "        img = img.convert('RGB')  \n",
    "        # img = img.convert('L')\n",
    "        resize = transforms.Resize((224, 224))  \n",
    "        img = resize(img)  \n",
    "        to_tensor = transforms.ToTensor()\n",
    "        img = to_tensor(img) \n",
    "        if self.data_type == 'test':\n",
    "            y = sample[1]\n",
    "        else:\n",
    "            y = self.classes.index(sample[1])\n",
    "        return img,y\n",
    "    \n",
    "def test(test_loader,weights,device,model_name,index):\n",
    "    net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 62))\n",
    "    net.load_state_dict(torch.load(weights,weights_only=True))\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    # print('test模型加载完毕',torch.cuda.memory_allocated()//1024//1024,torch.cuda.memory_reserved()//1024//1024)\n",
    "    with open(data_root/Path('classes.txt'),'r',encoding='utf-8') as rf:\n",
    "        classes = rf.read().split(',')\n",
    "    with open(data_root/Path('classes.json'),'r',encoding='utf-8') as rf:\n",
    "        classes_json=json.loads(rf.read())\n",
    "    result = list()\n",
    "    for data, name in test_loader:\n",
    "        # print('test数据准备加载',torch.cuda.memory_allocated()//1024//1024,torch.cuda.memory_reserved()//1024//1024)\n",
    "        data = data.to(device)\n",
    "        # print('test数据加载完成',torch.cuda.memory_allocated()//1024//1024,torch.cuda.memory_reserved()//1024//1024)\n",
    "        output=net(data)\n",
    "        # print('test模型预测完成',torch.cuda.memory_allocated()//1024//1024,torch.cuda.memory_reserved()//1024//1024)\n",
    "        predicted_class = torch.argmax(output,dim=1) \n",
    "        for i,j in zip(name,predicted_class.tolist()):\n",
    "            result.append('{},{}'.format(i,classes_json[classes[j]]))\n",
    "    with open('result/{}_cross_{}_{}.csv'.format(model_name,index,datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")),'w',encoding='utf-8') as wf:\n",
    "        wf.write('ImageID,label\\n')\n",
    "        wf.write('\\n'.join(result))\n",
    "    print('测试完成',torch.cuda.memory_allocated()//1024//1024)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # print('strat...',torch.cuda.memory_allocated()//1024//1024)\n",
    "    datasets_root = Path('../data/traffic_sign/')\n",
    "    data_root = Path('./data/traffic_sign/split_1/')\n",
    "    dataset(datasets_root)\n",
    "    batch_size = 208\n",
    "    model_name = 'GoogLeNet-0004'\n",
    "    parser = argparse.ArgumentParser(description='')  \n",
    "    parser.add_argument('--index', type=str, help='交叉验证的划分号',default=0)\n",
    "    args = parser.parse_args()\n",
    "    cross_index = int(args.index)\n",
    "    # print('加载训练集和验证集',torch.cuda.memory_allocated()//1024//1024)\n",
    "    train_loader = DataLoader(dataset=TrafficSign(datasets_root,data_root,'train'),batch_size=batch_size,shuffle=True)\n",
    "    val_loader = DataLoader(dataset=TrafficSign(datasets_root,data_root,'val'),batch_size=batch_size,shuffle=True)\n",
    "    lr, num_epochs = 0.05, 80\n",
    "    train_ch6( train_loader, val_loader, num_epochs, lr, d2l.try_gpu(), model_name, cross_index)\n",
    "    print('开始测试',torch.cuda.memory_allocated()//1024//1024)\n",
    "    test_loader = DataLoader(dataset=TrafficSign(datasets_root,data_root,'test'),batch_size=batch_size)\n",
    "    test(test_loader,'weights/{}_{}_best_weights.pth'.format(model_name,cross_index),d2l.try_gpu(), model_name,cross_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd1731-7611-477f-8ec6-f73688420d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m模型定义Alex模型\n",
    "net = nn.Sequential(\n",
    "    # 这⾥，我们使⽤⼀个11*11的更⼤窗⼝来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的⾼度和宽度。\n",
    "    # 另外，输出通道的数⽬远⼤于LeNet\n",
    "    nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减⼩卷积窗⼝，使⽤填充为2来使得输⼊与输出的⾼和宽⼀致，且增⼤输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使⽤三个连续的卷积层和较⼩的卷积窗⼝。\n",
    "    # 除了最后的卷积层，输出通道的数量进⼀步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不⽤于减少输⼊的⾼度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这⾥，全连接层的输出数量是LeNet中的好⼏倍。使⽤dropout层来减轻过度拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这⾥使⽤Fashion-MNIST，所以⽤类别数为10，⽽⾮论⽂中的1000\n",
    "    nn.Linear(4096, 62))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aebd83-819e-4f6e-9690-ab58650b48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from pathlib import Path\n",
    "from torchvision import transforms  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from PIL import Image  \n",
    "import argparse \n",
    "import time\n",
    "from models.ResNet import ResNet\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(14, 10),model_name='',index=''):\n",
    "        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "        self.model_name=model_name\n",
    "        self.index = index\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        self.fig.savefig('log/log_{}_{}.png'.format(self.model_name,self.index))\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使⽤GPU计算模型在数据集上的精度。\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval() # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X, list):\n",
    "            # BERT微调所需的（之后将介绍）\n",
    "            X = [x.to(device) for x in X]\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "        \n",
    "class TrafficSign(Dataset):  \n",
    "    def __init__(self, data_file, dataset_root):  \n",
    "        self.transforms = [\n",
    "            lambda x:x,\n",
    "            transforms.RandomHorizontalFlip(),  # 左右翻转\n",
    "            transforms.RandomVerticalFlip(),  # 垂直翻转\n",
    "            transforms.RandomRotation((45,45)),   # 旋转45度\n",
    "            transforms.RandomRotation((90,90)),   # 旋转45度\n",
    "            transforms.RandomRotation((135,135)),   # 旋转45度\n",
    "            transforms.RandomRotation((180,180)),   # 旋转45度\n",
    "            transforms.RandomRotation((225,225)),   # 旋转45度\n",
    "            transforms.RandomRotation((270,270)),   # 旋转45度\n",
    "            transforms.RandomRotation((315,315)),   # 旋转45度\n",
    "            transforms.RandomAffine(0,translate=(0.3,0.3)),  # 平移\n",
    "            transforms.RandomAffine(0,translate=(0.3,0.3)),  # 平移\n",
    "            transforms.RandomAffine(0,translate=(0.3,0.3)),  # 平移\n",
    "            transforms.RandomAffine(0,translate=(0.3,0.3)),  # 平移\n",
    "            lambda x:transforms.Resize((x.size[0], x.size[1]//2))(x),   # 横向缩放\n",
    "            lambda x:transforms.Resize((x.size[0]//2, x.size[1]))(x),   # 纵向缩放\n",
    "            transforms.GaussianBlur(7, 3),  # 高斯模糊\n",
    "            lambda x:Image.fromarray(iaa.MotionBlur(k=15, angle=0)(image = np.array(x)[:, :, ::-1] )),  # 运动模糊\n",
    "            lambda x:transforms.Resize((30, 30))(transforms.ColorJitter(brightness=0.1, contrast=0.1)(x)), # 降低亮度并缩小\n",
    "            ]\n",
    "        with open(data_file,'r',encoding='utf-8') as rf:\n",
    "            self.data = list()\n",
    "            for pic in [i.split(',') for i in rf.read().split('\\n') if i]:\n",
    "                for j in range(len(self.transforms)):\n",
    "                    if int(pic[1]) in [21,23,25,26,27,28,33,34,50,53,55] and j in [1]:\n",
    "                        continue\n",
    "                    self.data.append([pic[0]+'_{}'.format(j),pic[1]])\n",
    "        self.dataset_root = dataset_root\n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):  \n",
    "        sample = self.data[idx]\n",
    "        img = Image.open(self.dataset_root/Path(sample[0][:sample[0].rfind('_')])) # 打开图片，\n",
    "        img = img.convert('RGB')   # 首先统一为RGB的形式，然后进行处理\n",
    "        img = self.transforms[int(sample[0][sample[0].rfind('_')+1:])](img) # 数据增强处理  \n",
    "        img = img.convert('L') # 改为单通道\n",
    "        img = transforms.Resize((96, 96))(img) # 统一大小\n",
    "        img = transforms.ToTensor()(img) \n",
    "        y = int(sample[1])\n",
    "        return img,y\n",
    "    \n",
    "def process_bar(progress,total):\n",
    "        # 计算当前进度条的百分比  \n",
    "        percent = (progress / total) * 100  \n",
    "        # 构造进度条字符串，使用空格来填充剩余部分  \n",
    "        bar = f'[{\">\" * int(percent)}' + ' ' * (100 - int(percent)) + f']'  +' {}/{}'.format(progress,total)\n",
    "        # 使用\\r回到行首，然后打印进度条  \n",
    "        print(f'\\r{bar}', end='', flush=True)    \n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m)==nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = d2l.try_gpu()\n",
    "    print('train on {}'.format(device))\n",
    "    # 首先加载数据，数据应该是csv的，存储样本和标签的信息\n",
    "    print('load data...')\n",
    "    datasets_root = Path('../data/traffic_sign/')\n",
    "    data_root = Path('./data/traffic_sign_B/')\n",
    "    # 确定是交叉验证的哪一个\n",
    "    parser = argparse.ArgumentParser(description='')     \n",
    "    parser.add_argument('--index', type=str, help='交叉验证的划分号',default=0)\n",
    "    cross_index = int(parser.parse_args().index)\n",
    "    ## 加载数据\n",
    "    batch_size = 512\n",
    "    train_dataset = TrafficSign(data_root/'train_{}.csv'.format(cross_index),datasets_root)\n",
    "    train_iter = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "    test_dataset = TrafficSign(data_root/'test_{}.csv'.format(cross_index),datasets_root)\n",
    "    test_iter = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n",
    "    # num = 0\n",
    "    # for i in test_iter:\n",
    "    #     num+=i[0].shape[0]\n",
    "    # print(num)\n",
    "    # quit()\n",
    "    # 构建模型\n",
    "    print('generate model...')\n",
    "    lr, num_epochs = 0.05, 5\n",
    "    net  = ResNet\n",
    "    net.apply(init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    # 开始训练\n",
    "    print('start train...')\n",
    "    model_name = 'ResNet-B-0002'\n",
    "    animator = Animator(xlabel='epoch',xlim=[1,num_epochs],legend=['train loss','train acc','test acc'],model_name=model_name,index=cross_index)\n",
    "    num_batches = len(train_iter)\n",
    "    best_acc = 0\n",
    "    with open('log/log_{}_{}.log'.format(model_name,cross_index),'w',encoding='utf-8') as wf:\n",
    "        wf.write('')\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.perf_counter()\n",
    "        out_str = '{}-cross_{}_epoch:{}/{}\\t'.format(model_name,cross_index,epoch,num_epochs)\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i,(X,y) in enumerate(train_iter):\n",
    "            optimizer.zero_grad()\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat,y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l*X.shape[0],d2l.accuracy(y_hat,y),X.shape[0])\n",
    "            train_l = metric[0]/metric[2]\n",
    "            train_acc = metric[1]/metric[2]\n",
    "            if (i+1)%(num_batches//5)==0 or i==num_batches-1:\n",
    "                animator.add(epoch+(i+1)/num_batches,(train_l,train_acc,None))\n",
    "            process_bar(i,num_batches)\n",
    "        test_acc = evaluate_accuracy_gpu(net,test_iter)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc = test_acc\n",
    "            weights_path = Path('./weights/')\n",
    "            weights_path.mkdir(parents=True, exist_ok=True)\n",
    "            if best_acc>0.9:\n",
    "                torch.save(net.state_dict(),weights_path/Path('{}_{}_best_weights.pth'.format(model_name,cross_index)))\n",
    "        # torch.save(net.state_dict(), weights_path/Path('{}_{}_last_weights.pth'.format(model_name,index)))\n",
    "        animator.add(epoch+1,(None,None,test_acc))\n",
    "        with open('log/log_{}_{}.log'.format(model_name,cross_index),'a',encoding='utf-8') as wf:\n",
    "            wf.write(out_str+'\\n')\n",
    "        process_time = time.perf_counter()-start_time\n",
    "        out_str+=f'loss {train_l:.3f},train acc {train_acc:.3f},'f'test acc {test_acc:.3f},'f'time {process_time:.3f}s'\n",
    "        print(f'\\r'+' '*120, end = '', flush=True)  \n",
    "        print(f'\\r'+out_str)  \n",
    "    print(weights_path/Path('{}_{}_best_weights.pth'.format(model_name,cross_index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeda8c2-b9fc-47dc-8541-21bc8bad1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型测试\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms  \n",
    "from sklearn.model_selection import train_test_split # pip install scikit-learn \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from PIL import Image  \n",
    "import json\n",
    "from datetime import datetime\n",
    "import argparse \n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(14, 10),model_name='',index=''):\n",
    "        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "        self.model_name=model_name\n",
    "        self.index = index\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        self.fig.savefig('log/log_{}_{}.png'.format(self.model_name,self.index))\n",
    "\n",
    "class Residual(nn.Module): #@save\n",
    "    def __init__(self, input_channels, num_channels,use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "def resnet_block(input_channels, num_channels, num_residuals,first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),nn.BatchNorm2d(64), nn.ReLU(),nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))\n",
    "\n",
    "# net = nn.Sequential(b1, b2, b3, b4, b5,nn.AdaptiveAvgPool2d((1,1)),nn.Flatten(), nn.Linear(512, 10))\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使⽤GPU计算模型在数据集上的精度。\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval() # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X, list):\n",
    "            # BERT微调所需的（之后将介绍）\n",
    "            X = [x.to(device) for x in X]\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "\n",
    "def split_dataset(datasets_root,data_root,exist_ok=True):\n",
    "    test_path = datasets_root/Path('test_set_B')\n",
    "    X_test = [item.relative_to(datasets_root) for item in test_path.rglob('*') if item.is_file()]\n",
    "    with open(data_root/Path('test_B.csv'),'w',encoding='utf-8') as wf:\n",
    "        wf.write('\\n'.join([str(i) for i in X_test]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dataset(data_root):\n",
    "    '''准备数据集\n",
    "    '''\n",
    "    data_root.mkdir(parents=True, exist_ok=True)\n",
    "    # 检查是否存在训练集文件,没有则创建\n",
    "    if not (data_root/Path('train_set')).exists():\n",
    "        datasets.utils.download_and_extract_archive('https://ai-contest-static.xfyun.cn/2024/%E4%BA%A4%E9%80%9A%E6%A0%87%E8%AF%86%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%E8%B5%9B/train_set.zip',data_root,data_root)\n",
    "    if not (data_root/Path('test_set')).exists():\n",
    "        datasets.utils.download_and_extract_archive('https://ai-contest-static.xfyun.cn/2024/%E4%BA%A4%E9%80%9A%E6%A0%87%E8%AF%86%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%E8%B5%9B/test_set.zip',data_root,data_root)\n",
    "    if not (data_root/Path('example.csv')).exists():\n",
    "        datasets.utils.download_url('https://ai-contest-static.xfyun.cn/2024/%E4%BA%A4%E9%80%9A%E6%A0%87%E8%AF%86%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%E8%B5%9B/example.csv',data_root)\n",
    "\n",
    "class TrafficSign(Dataset):  \n",
    "    def __init__(self, data_file,class_file, dataset_root,label=True):  \n",
    "        if label:\n",
    "            with open(data_file,'r',encoding='utf-8') as rf:\n",
    "                self.data = [i.split(',') for i in rf.read().split('\\n') if i]\n",
    "        else:\n",
    "            with open(data_file,'r',encoding='utf-8') as rf:\n",
    "                self.data = [[i,Path(i).name] for i in rf.read().split('\\n')] \n",
    "        with open(class_file,'r',encoding='utf-8') as rf:\n",
    "            self.classes = rf.read().split(',')\n",
    "        self.label = label\n",
    "        self.dataset_root = dataset_root\n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):  \n",
    "        sample = self.data[idx]\n",
    "        img = Image.open(self.dataset_root/Path(sample[0]))\n",
    "        # 图片处理\n",
    "        # img = img.convert('RGB')  \n",
    "        img = img.convert('L')\n",
    "        resize = transforms.Resize((96, 96))  \n",
    "        img = resize(img)  \n",
    "        to_tensor = transforms.ToTensor()\n",
    "        img = to_tensor(img) \n",
    "        if not self.label:\n",
    "            y = sample[1]\n",
    "        else:\n",
    "            y = self.classes.index(sample[1])\n",
    "        return img,y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = d2l.try_gpu()\n",
    "    print('test on {}'.format(device))\n",
    "    # 首先加载数据，数据应该是csv的，存储样本和标签的信息\n",
    "    datasets_root = Path('../data/traffic_sign/')\n",
    "    data_root = Path('./data/traffic_sign/')\n",
    "    batch_size = 512\n",
    "    dataset = TrafficSign(data_file = data_root/'test.csv',class_file=data_root/'classes.txt',dataset_root=datasets_root)\n",
    "    test_loader = DataLoader(dataset=dataset,batch_size=batch_size)\n",
    "    #for i in test_loader:\n",
    "    #    print(len(i),i[0].shape,i[1].shape)\n",
    "    #    quit()\n",
    "    # 加载模型和训练好的参数\n",
    "    from models.ResNet import ResNet\n",
    "    net  = ResNet\n",
    "    weights = 'weights/ResNet-0000_0_best_weights.pth'\n",
    "    net.load_state_dict(torch.load(weights,weights_only=True))\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    # 开始测试\n",
    "    sample_num, right_num = 0,0\n",
    "    for data, name in test_loader:\n",
    "        data = data.to(device)\n",
    "        output=net(data)\n",
    "        predicted_class = torch.argmax(output,dim=1)\n",
    "        for i,j in zip(name,predicted_class.tolist()):\n",
    "            if i==j:\n",
    "                right_num+=1\n",
    "            sample_num+=1\n",
    "    print('{}/{},{:.4f}'.format(right_num,sample_num,right_num/sample_num))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1b0d3-8d5d-4803-a6ec-0a81852e9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准确度评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93c967-1c8c-44f8-a082-acb7b51b1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型推理\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms  \n",
    "from sklearn.model_selection import train_test_split # pip install scikit-learn \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from PIL import Image  \n",
    "import json\n",
    "from datetime import datetime\n",
    "import argparse \n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "import mimetypes\n",
    "from models.ResNet import ResNet\n",
    "\n",
    "class TrafficSign(Dataset):  \n",
    "    def __init__(self, data_source, dataset_root):\n",
    "        if data_source.is_file(): # 判断输入是不是文件\n",
    "            if is_binary_file(data_source): # 如果是二进制文件，默认是输入一张图片\n",
    "                pass\n",
    "            else: # 如果不是二进制文件，默认是一个存储图片路径的文档\n",
    "                with open(data_source,'r',encoding='utf-8') as rf:\n",
    "                    self.data = [[i.split(',')[0],Path(i.split(',')[0]).name] for i in rf.read().split('\\n') if i]\n",
    "                # print(self.data)\n",
    "        else: # 如果是一个文件夹，默认是存储图片的文件夹\n",
    "            pass\n",
    "        self.dataset_root = dataset_root\n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):  \n",
    "        sample = self.data[idx]\n",
    "        img = Image.open(self.dataset_root/Path(sample[0]))\n",
    "        # 图片处理\n",
    "        img = img.convert('RGB')  \n",
    "        # img = img.convert('L')\n",
    "        resize = transforms.Resize((96, 96))  \n",
    "        img = resize(img)  \n",
    "        to_tensor = transforms.ToTensor()\n",
    "        img = to_tensor(img) \n",
    "        y = sample[1]\n",
    "        return img,y\n",
    "\n",
    "\n",
    "\n",
    "def is_binary_file(file_path):\n",
    "    mime_type, encoding = mimetypes.guess_type(file_path)\n",
    "    return mime_type is None or mime_type.startswith('application/') or 'image' in mime_type\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = d2l.try_gpu()\n",
    "    print('infer on {}'.format(device))\n",
    "    # 首先加载数据，数据应该是csv的，存储样本和标签的信息,也可以是一个文件夹\n",
    "    data_source = Path('./data/traffic_sign/test_B.csv')\n",
    "    datasets_root = Path('../data/traffic_sign/')\n",
    "    data_root = Path('./data/traffic_sign/')\n",
    "    batch_size = 512\n",
    "    dataset = TrafficSign(data_source, datasets_root)\n",
    "    test_loader = DataLoader(dataset=dataset,batch_size=batch_size)\n",
    "    # 确定是交叉验证的哪一个\n",
    "    parser = argparse.ArgumentParser(description='')  \n",
    "    parser.add_argument('--index', type=str, help='交叉验证的划分号',default=0)\n",
    "    cross_index = int(parser.parse_args().index)\n",
    "    # 加载模型和训练好的参数\\\n",
    "    model_name = 'ResNet-B-0001'\n",
    "    net  = ResNet\n",
    "    weights = 'weights/{}_{}_best_weights.pth'.format(model_name,cross_index)\n",
    "    net.load_state_dict(torch.load(weights,weights_only=True))\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    # 开始推理\n",
    "    result = list()\n",
    "    sample_num, right_num = 0,0\n",
    "    for data, name in test_loader:\n",
    "        data = data.to(device)\n",
    "        output=net(data)\n",
    "        predicted_class = torch.argmax(output,dim=1)\n",
    "        for i,j in zip(name,predicted_class.tolist()):\n",
    "            result.append([str(i),str(j)])\n",
    "    with open('result/{}_cross_{}_{}.csv'.format(model_name,cross_index,datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")),'w',encoding='utf-8') as wf:\n",
    "        wf.write('ImageID,label\\n')\n",
    "        for i in result:\n",
    "            wf.write(','.join(i)+'\\n')\n",
    "    print('{} infer over'.format(cross_index))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "panel-cell-order": [
   "9e2a15a9-efc8-4b4a-b651-6cc44ccf8ab9"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
